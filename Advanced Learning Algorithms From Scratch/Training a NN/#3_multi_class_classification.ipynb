{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (40000, 2)\n",
      "Shape of y: (40000,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "num_samples = 10000\n",
    "class_0_mean = [2, 2]\n",
    "class_0_cov = [[1, 0.5], [0.5, 1]]\n",
    "class_0_data = np.random.multivariate_normal(class_0_mean, class_0_cov, num_samples)\n",
    "\n",
    "class_1_mean = [-2, 2]\n",
    "class_1_cov = [[1, -0.5], [-0.5, 1]]\n",
    "class_1_data = np.random.multivariate_normal(class_1_mean, class_1_cov, num_samples)\n",
    "\n",
    "class_2_mean = [-2, -2]\n",
    "class_2_cov = [[1, 0.5], [0.5, 1]]\n",
    "class_2_data = np.random.multivariate_normal(class_2_mean, class_2_cov, num_samples)\n",
    "\n",
    "class_3_mean = [2, -2]\n",
    "class_3_cov = [[1, -0.5], [-0.5, 1]]\n",
    "class_3_data = np.random.multivariate_normal(class_3_mean, class_3_cov, num_samples)\n",
    "\n",
    "X = np.vstack([class_0_data, class_1_data, class_2_data, class_3_data])\n",
    "y = np.concatenate([np.zeros(num_samples), np.ones(num_samples), 2 * np.ones(num_samples), 3 * np.ones(num_samples)])\n",
    "\n",
    "shuffle_indices = np.random.permutation(X.shape[0])\n",
    "X = X[shuffle_indices]\n",
    "y = y[shuffle_indices]\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softmax(z):\n",
    "    ax = np.exp(z) / np.sum(np.exp(z))\n",
    "    return ax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Softmax: [0.0320586  0.08714432 0.23688282 0.6439142 ], Tensorflow Softmax: [0.0320586  0.08714432 0.23688284 0.6439143 ]\n"
     ]
    }
   ],
   "source": [
    "z = np.arange(1, 5).astype('float32')\n",
    "\n",
    "print(f\"My Softmax: {my_softmax(z)}, Tensorflow Softmax: {tf.nn.softmax(z)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 25)                75        \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 15)                390       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 4)                 64        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 529 (2.07 KB)\n",
      "Trainable params: 529 (2.07 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential ([\n",
    "    Input(shape=(X.shape[1])),\n",
    "    Dense(25, activation='relu'),\n",
    "    Dense(15, activation='relu'),\n",
    "    Dense(4, activation='linear')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "875/875 [==============================] - 1s 566us/step - loss: 0.2146 - accuracy: 0.9414 - val_loss: 0.1258 - val_accuracy: 0.9568\n",
      "Epoch 2/100\n",
      "875/875 [==============================] - 0s 510us/step - loss: 0.1180 - accuracy: 0.9582 - val_loss: 0.1264 - val_accuracy: 0.9557\n",
      "Epoch 3/100\n",
      "875/875 [==============================] - 0s 507us/step - loss: 0.1176 - accuracy: 0.9581 - val_loss: 0.1270 - val_accuracy: 0.9559\n",
      "Epoch 4/100\n",
      "875/875 [==============================] - 0s 503us/step - loss: 0.1172 - accuracy: 0.9586 - val_loss: 0.1248 - val_accuracy: 0.9572\n",
      "Epoch 5/100\n",
      "875/875 [==============================] - 0s 500us/step - loss: 0.1169 - accuracy: 0.9591 - val_loss: 0.1246 - val_accuracy: 0.9560\n",
      "Epoch 6/100\n",
      "875/875 [==============================] - 0s 499us/step - loss: 0.1165 - accuracy: 0.9585 - val_loss: 0.1240 - val_accuracy: 0.9563\n",
      "Epoch 7/100\n",
      "875/875 [==============================] - 0s 497us/step - loss: 0.1165 - accuracy: 0.9581 - val_loss: 0.1246 - val_accuracy: 0.9556\n",
      "Epoch 8/100\n",
      "875/875 [==============================] - 0s 518us/step - loss: 0.1163 - accuracy: 0.9586 - val_loss: 0.1230 - val_accuracy: 0.9572\n",
      "Epoch 9/100\n",
      "875/875 [==============================] - 0s 499us/step - loss: 0.1158 - accuracy: 0.9587 - val_loss: 0.1231 - val_accuracy: 0.9563\n",
      "Epoch 10/100\n",
      "875/875 [==============================] - 0s 510us/step - loss: 0.1156 - accuracy: 0.9587 - val_loss: 0.1241 - val_accuracy: 0.9567\n",
      "Epoch 11/100\n",
      "875/875 [==============================] - 0s 559us/step - loss: 0.1158 - accuracy: 0.9581 - val_loss: 0.1242 - val_accuracy: 0.9559\n",
      "Epoch 12/100\n",
      "875/875 [==============================] - 0s 506us/step - loss: 0.1155 - accuracy: 0.9584 - val_loss: 0.1233 - val_accuracy: 0.9562\n",
      "Epoch 13/100\n",
      "875/875 [==============================] - 0s 488us/step - loss: 0.1154 - accuracy: 0.9584 - val_loss: 0.1246 - val_accuracy: 0.9557\n",
      "Epoch 14/100\n",
      "875/875 [==============================] - 0s 492us/step - loss: 0.1155 - accuracy: 0.9589 - val_loss: 0.1229 - val_accuracy: 0.9560\n",
      "Epoch 15/100\n",
      "875/875 [==============================] - 0s 499us/step - loss: 0.1155 - accuracy: 0.9585 - val_loss: 0.1249 - val_accuracy: 0.9553\n",
      "Epoch 16/100\n",
      "875/875 [==============================] - 0s 571us/step - loss: 0.1152 - accuracy: 0.9584 - val_loss: 0.1264 - val_accuracy: 0.9552\n",
      "Epoch 17/100\n",
      "875/875 [==============================] - 0s 523us/step - loss: 0.1150 - accuracy: 0.9587 - val_loss: 0.1226 - val_accuracy: 0.9560\n",
      "Epoch 18/100\n",
      "875/875 [==============================] - 0s 521us/step - loss: 0.1151 - accuracy: 0.9583 - val_loss: 0.1232 - val_accuracy: 0.9566\n",
      "Epoch 19/100\n",
      "875/875 [==============================] - 0s 528us/step - loss: 0.1150 - accuracy: 0.9588 - val_loss: 0.1223 - val_accuracy: 0.9563\n",
      "Epoch 20/100\n",
      "875/875 [==============================] - 0s 499us/step - loss: 0.1152 - accuracy: 0.9577 - val_loss: 0.1224 - val_accuracy: 0.9557\n",
      "Epoch 21/100\n",
      "875/875 [==============================] - 0s 500us/step - loss: 0.1151 - accuracy: 0.9583 - val_loss: 0.1231 - val_accuracy: 0.9560\n",
      "Epoch 22/100\n",
      "875/875 [==============================] - 0s 497us/step - loss: 0.1150 - accuracy: 0.9589 - val_loss: 0.1245 - val_accuracy: 0.9561\n",
      "Epoch 23/100\n",
      "875/875 [==============================] - 0s 522us/step - loss: 0.1150 - accuracy: 0.9582 - val_loss: 0.1234 - val_accuracy: 0.9559\n",
      "Epoch 24/100\n",
      "875/875 [==============================] - 0s 496us/step - loss: 0.1152 - accuracy: 0.9585 - val_loss: 0.1259 - val_accuracy: 0.9553\n",
      "Epoch 25/100\n",
      "875/875 [==============================] - 0s 494us/step - loss: 0.1149 - accuracy: 0.9584 - val_loss: 0.1274 - val_accuracy: 0.9553\n",
      "Epoch 26/100\n",
      "875/875 [==============================] - 0s 521us/step - loss: 0.1148 - accuracy: 0.9580 - val_loss: 0.1253 - val_accuracy: 0.9559\n",
      "Epoch 27/100\n",
      "875/875 [==============================] - 0s 506us/step - loss: 0.1149 - accuracy: 0.9589 - val_loss: 0.1231 - val_accuracy: 0.9552\n",
      "Epoch 28/100\n",
      "875/875 [==============================] - 0s 516us/step - loss: 0.1149 - accuracy: 0.9585 - val_loss: 0.1231 - val_accuracy: 0.9557\n",
      "Epoch 29/100\n",
      "875/875 [==============================] - 0s 497us/step - loss: 0.1147 - accuracy: 0.9585 - val_loss: 0.1242 - val_accuracy: 0.9557\n",
      "Epoch 30/100\n",
      "875/875 [==============================] - 0s 516us/step - loss: 0.1147 - accuracy: 0.9586 - val_loss: 0.1234 - val_accuracy: 0.9561\n",
      "Epoch 31/100\n",
      "875/875 [==============================] - 0s 491us/step - loss: 0.1148 - accuracy: 0.9584 - val_loss: 0.1236 - val_accuracy: 0.9551\n",
      "Epoch 32/100\n",
      "875/875 [==============================] - 0s 506us/step - loss: 0.1150 - accuracy: 0.9583 - val_loss: 0.1235 - val_accuracy: 0.9562\n",
      "Epoch 33/100\n",
      "875/875 [==============================] - 0s 537us/step - loss: 0.1147 - accuracy: 0.9588 - val_loss: 0.1235 - val_accuracy: 0.9554\n",
      "Epoch 34/100\n",
      "875/875 [==============================] - 0s 525us/step - loss: 0.1149 - accuracy: 0.9579 - val_loss: 0.1238 - val_accuracy: 0.9556\n",
      "Epoch 35/100\n",
      "875/875 [==============================] - 0s 496us/step - loss: 0.1146 - accuracy: 0.9586 - val_loss: 0.1252 - val_accuracy: 0.9548\n",
      "Epoch 36/100\n",
      "875/875 [==============================] - 0s 495us/step - loss: 0.1148 - accuracy: 0.9585 - val_loss: 0.1236 - val_accuracy: 0.9557\n",
      "Epoch 37/100\n",
      "875/875 [==============================] - 0s 536us/step - loss: 0.1148 - accuracy: 0.9588 - val_loss: 0.1237 - val_accuracy: 0.9555\n",
      "Epoch 38/100\n",
      "875/875 [==============================] - 0s 512us/step - loss: 0.1146 - accuracy: 0.9586 - val_loss: 0.1224 - val_accuracy: 0.9553\n",
      "Epoch 39/100\n",
      "875/875 [==============================] - 0s 496us/step - loss: 0.1147 - accuracy: 0.9587 - val_loss: 0.1222 - val_accuracy: 0.9557\n",
      "Epoch 40/100\n",
      "875/875 [==============================] - 0s 500us/step - loss: 0.1147 - accuracy: 0.9585 - val_loss: 0.1244 - val_accuracy: 0.9558\n",
      "Epoch 41/100\n",
      "875/875 [==============================] - 0s 510us/step - loss: 0.1148 - accuracy: 0.9584 - val_loss: 0.1240 - val_accuracy: 0.9549\n",
      "Epoch 42/100\n",
      "875/875 [==============================] - 1s 587us/step - loss: 0.1147 - accuracy: 0.9584 - val_loss: 0.1219 - val_accuracy: 0.9563\n",
      "Epoch 43/100\n",
      "875/875 [==============================] - 0s 517us/step - loss: 0.1145 - accuracy: 0.9588 - val_loss: 0.1233 - val_accuracy: 0.9561\n",
      "Epoch 44/100\n",
      "875/875 [==============================] - 0s 564us/step - loss: 0.1146 - accuracy: 0.9588 - val_loss: 0.1224 - val_accuracy: 0.9562\n",
      "Epoch 45/100\n",
      "875/875 [==============================] - 0s 529us/step - loss: 0.1147 - accuracy: 0.9583 - val_loss: 0.1242 - val_accuracy: 0.9552\n",
      "Epoch 46/100\n",
      "875/875 [==============================] - 0s 545us/step - loss: 0.1146 - accuracy: 0.9583 - val_loss: 0.1224 - val_accuracy: 0.9566\n",
      "Epoch 47/100\n",
      "875/875 [==============================] - 0s 504us/step - loss: 0.1147 - accuracy: 0.9585 - val_loss: 0.1229 - val_accuracy: 0.9560\n",
      "Epoch 48/100\n",
      "875/875 [==============================] - 0s 500us/step - loss: 0.1146 - accuracy: 0.9585 - val_loss: 0.1223 - val_accuracy: 0.9566\n",
      "Epoch 49/100\n",
      "875/875 [==============================] - 0s 498us/step - loss: 0.1147 - accuracy: 0.9582 - val_loss: 0.1241 - val_accuracy: 0.9560\n",
      "Epoch 50/100\n",
      "875/875 [==============================] - 0s 502us/step - loss: 0.1145 - accuracy: 0.9584 - val_loss: 0.1225 - val_accuracy: 0.9557\n",
      "Epoch 51/100\n",
      "875/875 [==============================] - 0s 500us/step - loss: 0.1146 - accuracy: 0.9585 - val_loss: 0.1224 - val_accuracy: 0.9563\n",
      "Epoch 52/100\n",
      "875/875 [==============================] - 0s 501us/step - loss: 0.1145 - accuracy: 0.9585 - val_loss: 0.1233 - val_accuracy: 0.9557\n",
      "Epoch 53/100\n",
      "875/875 [==============================] - 0s 529us/step - loss: 0.1145 - accuracy: 0.9583 - val_loss: 0.1236 - val_accuracy: 0.9561\n",
      "Epoch 54/100\n",
      "875/875 [==============================] - 0s 499us/step - loss: 0.1145 - accuracy: 0.9578 - val_loss: 0.1227 - val_accuracy: 0.9560\n",
      "Epoch 55/100\n",
      "875/875 [==============================] - 0s 491us/step - loss: 0.1141 - accuracy: 0.9585 - val_loss: 0.1247 - val_accuracy: 0.9557\n",
      "Epoch 56/100\n",
      "875/875 [==============================] - 0s 503us/step - loss: 0.1143 - accuracy: 0.9588 - val_loss: 0.1227 - val_accuracy: 0.9558\n",
      "Epoch 57/100\n",
      "875/875 [==============================] - 0s 497us/step - loss: 0.1145 - accuracy: 0.9586 - val_loss: 0.1225 - val_accuracy: 0.9569\n",
      "Epoch 58/100\n",
      "875/875 [==============================] - 0s 498us/step - loss: 0.1147 - accuracy: 0.9585 - val_loss: 0.1228 - val_accuracy: 0.9557\n",
      "Epoch 59/100\n",
      "875/875 [==============================] - 0s 499us/step - loss: 0.1145 - accuracy: 0.9582 - val_loss: 0.1222 - val_accuracy: 0.9561\n",
      "Epoch 60/100\n",
      "875/875 [==============================] - 1s 586us/step - loss: 0.1144 - accuracy: 0.9584 - val_loss: 0.1229 - val_accuracy: 0.9557\n",
      "Epoch 61/100\n",
      "875/875 [==============================] - 0s 496us/step - loss: 0.1144 - accuracy: 0.9581 - val_loss: 0.1224 - val_accuracy: 0.9563\n",
      "Epoch 62/100\n",
      "875/875 [==============================] - 0s 537us/step - loss: 0.1144 - accuracy: 0.9590 - val_loss: 0.1229 - val_accuracy: 0.9556\n",
      "Epoch 63/100\n",
      "875/875 [==============================] - 0s 506us/step - loss: 0.1146 - accuracy: 0.9589 - val_loss: 0.1226 - val_accuracy: 0.9558\n",
      "Epoch 64/100\n",
      "875/875 [==============================] - 0s 498us/step - loss: 0.1140 - accuracy: 0.9588 - val_loss: 0.1233 - val_accuracy: 0.9559\n",
      "Epoch 65/100\n",
      "875/875 [==============================] - 0s 493us/step - loss: 0.1145 - accuracy: 0.9579 - val_loss: 0.1233 - val_accuracy: 0.9552\n",
      "Epoch 66/100\n",
      "875/875 [==============================] - 0s 492us/step - loss: 0.1144 - accuracy: 0.9588 - val_loss: 0.1220 - val_accuracy: 0.9564\n",
      "Epoch 67/100\n",
      "875/875 [==============================] - 0s 515us/step - loss: 0.1144 - accuracy: 0.9584 - val_loss: 0.1222 - val_accuracy: 0.9563\n",
      "Epoch 68/100\n",
      "875/875 [==============================] - 0s 496us/step - loss: 0.1143 - accuracy: 0.9584 - val_loss: 0.1225 - val_accuracy: 0.9561\n",
      "Epoch 69/100\n",
      "875/875 [==============================] - 0s 493us/step - loss: 0.1147 - accuracy: 0.9584 - val_loss: 0.1231 - val_accuracy: 0.9560\n",
      "Epoch 70/100\n",
      "875/875 [==============================] - 0s 496us/step - loss: 0.1143 - accuracy: 0.9587 - val_loss: 0.1234 - val_accuracy: 0.9557\n",
      "Epoch 71/100\n",
      "875/875 [==============================] - 0s 493us/step - loss: 0.1143 - accuracy: 0.9585 - val_loss: 0.1231 - val_accuracy: 0.9562\n",
      "Epoch 72/100\n",
      "875/875 [==============================] - 0s 494us/step - loss: 0.1144 - accuracy: 0.9584 - val_loss: 0.1220 - val_accuracy: 0.9566\n",
      "Epoch 73/100\n",
      "875/875 [==============================] - 0s 498us/step - loss: 0.1142 - accuracy: 0.9587 - val_loss: 0.1229 - val_accuracy: 0.9565\n",
      "Epoch 74/100\n",
      "875/875 [==============================] - 0s 525us/step - loss: 0.1142 - accuracy: 0.9587 - val_loss: 0.1234 - val_accuracy: 0.9554\n",
      "Epoch 75/100\n",
      "875/875 [==============================] - 0s 493us/step - loss: 0.1146 - accuracy: 0.9585 - val_loss: 0.1225 - val_accuracy: 0.9559\n",
      "Epoch 76/100\n",
      "875/875 [==============================] - 0s 519us/step - loss: 0.1145 - accuracy: 0.9582 - val_loss: 0.1228 - val_accuracy: 0.9550\n",
      "Epoch 77/100\n",
      "875/875 [==============================] - 0s 498us/step - loss: 0.1147 - accuracy: 0.9582 - val_loss: 0.1219 - val_accuracy: 0.9562\n",
      "Epoch 78/100\n",
      "875/875 [==============================] - 0s 500us/step - loss: 0.1143 - accuracy: 0.9587 - val_loss: 0.1228 - val_accuracy: 0.9559\n",
      "Epoch 79/100\n",
      "875/875 [==============================] - 0s 507us/step - loss: 0.1144 - accuracy: 0.9585 - val_loss: 0.1239 - val_accuracy: 0.9553\n",
      "Epoch 80/100\n",
      "875/875 [==============================] - 0s 495us/step - loss: 0.1143 - accuracy: 0.9582 - val_loss: 0.1224 - val_accuracy: 0.9563\n",
      "Epoch 81/100\n",
      "875/875 [==============================] - 0s 512us/step - loss: 0.1140 - accuracy: 0.9590 - val_loss: 0.1226 - val_accuracy: 0.9560\n",
      "Epoch 82/100\n",
      "875/875 [==============================] - 0s 498us/step - loss: 0.1144 - accuracy: 0.9583 - val_loss: 0.1237 - val_accuracy: 0.9555\n",
      "Epoch 83/100\n",
      "875/875 [==============================] - 0s 495us/step - loss: 0.1142 - accuracy: 0.9582 - val_loss: 0.1220 - val_accuracy: 0.9561\n",
      "Epoch 84/100\n",
      "875/875 [==============================] - 0s 507us/step - loss: 0.1145 - accuracy: 0.9585 - val_loss: 0.1243 - val_accuracy: 0.9558\n",
      "Epoch 85/100\n",
      "875/875 [==============================] - 0s 499us/step - loss: 0.1144 - accuracy: 0.9588 - val_loss: 0.1239 - val_accuracy: 0.9558\n",
      "Epoch 86/100\n",
      "875/875 [==============================] - 0s 501us/step - loss: 0.1143 - accuracy: 0.9586 - val_loss: 0.1270 - val_accuracy: 0.9541\n",
      "Epoch 87/100\n",
      "875/875 [==============================] - 0s 508us/step - loss: 0.1139 - accuracy: 0.9586 - val_loss: 0.1224 - val_accuracy: 0.9565\n",
      "Epoch 88/100\n",
      "875/875 [==============================] - 0s 513us/step - loss: 0.1141 - accuracy: 0.9587 - val_loss: 0.1243 - val_accuracy: 0.9557\n",
      "Epoch 89/100\n",
      "875/875 [==============================] - 0s 499us/step - loss: 0.1142 - accuracy: 0.9585 - val_loss: 0.1226 - val_accuracy: 0.9557\n",
      "Epoch 90/100\n",
      "875/875 [==============================] - 0s 504us/step - loss: 0.1145 - accuracy: 0.9588 - val_loss: 0.1224 - val_accuracy: 0.9557\n",
      "Epoch 91/100\n",
      "875/875 [==============================] - 0s 500us/step - loss: 0.1142 - accuracy: 0.9592 - val_loss: 0.1236 - val_accuracy: 0.9561\n",
      "Epoch 92/100\n",
      "875/875 [==============================] - 1s 660us/step - loss: 0.1142 - accuracy: 0.9585 - val_loss: 0.1235 - val_accuracy: 0.9553\n",
      "Epoch 93/100\n",
      "875/875 [==============================] - 0s 510us/step - loss: 0.1142 - accuracy: 0.9590 - val_loss: 0.1236 - val_accuracy: 0.9559\n",
      "Epoch 94/100\n",
      "875/875 [==============================] - 0s 532us/step - loss: 0.1143 - accuracy: 0.9584 - val_loss: 0.1232 - val_accuracy: 0.9555\n",
      "Epoch 95/100\n",
      "875/875 [==============================] - 0s 539us/step - loss: 0.1143 - accuracy: 0.9584 - val_loss: 0.1219 - val_accuracy: 0.9561\n",
      "Epoch 96/100\n",
      "875/875 [==============================] - 0s 505us/step - loss: 0.1141 - accuracy: 0.9585 - val_loss: 0.1234 - val_accuracy: 0.9553\n",
      "Epoch 97/100\n",
      "875/875 [==============================] - 0s 524us/step - loss: 0.1142 - accuracy: 0.9590 - val_loss: 0.1231 - val_accuracy: 0.9557\n",
      "Epoch 98/100\n",
      "875/875 [==============================] - 0s 543us/step - loss: 0.1142 - accuracy: 0.9584 - val_loss: 0.1242 - val_accuracy: 0.9553\n",
      "Epoch 99/100\n",
      "875/875 [==============================] - 0s 534us/step - loss: 0.1142 - accuracy: 0.9587 - val_loss: 0.1243 - val_accuracy: 0.9555\n",
      "Epoch 100/100\n",
      "875/875 [==============================] - 0s 519us/step - loss: 0.1141 - accuracy: 0.9588 - val_loss: 0.1231 - val_accuracy: 0.9553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a0daf310>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=SparseCategoricalCrossentropy(from_logits=True), optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=100, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
